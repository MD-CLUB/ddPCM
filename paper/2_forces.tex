\section{Computation of the ddPCM-Forces}\label{sec:forces}

\subsection{Theoretical Derivation}
%In the case of a classical solute, the form of the charge density $\rho$ allows to compute 
The solvation energy can be written as a sum of subdomain contributions, which perfectly fits the domain-decomposition paradigm. 

First, for a classical solute's charge distribution of the form of $\rho=\sum_j q_j \delta_{x_j}$, we can develop
\[
	E_s 
	= \frac{1}{2} \,  \int_{\Omega} \rho(x) W(x) \, dx
	= \frac{1}{2} \, \sum_j q_j  W(x_j)
	= 2 \pi \, \sum_j q_j [X_j]_0^0    \, Y_0^0
	= {\sqrt{\pi}}\, \sum_j q_j [X_j]_0^0
\]
{\color{red} (Paolo: the last two equalities are unclear to me.)}
This concept easily generalizes to point multipolar charge distributions. 
The evaluation of the energy for charge distributions is a bit more involved as it requires a three-dimensional integration and we refer to \cite{Lipparini_JCP_ddCOSMO-QM} for more details. In all cases however, the energy can be written as
\[
E_s = \tfrac{1}{2}
% \,f(\varepsilon)
 \, \sum_j \sum_{\ell,m} [\Psi_j]_\ell^m [X_j]_\ell^m
  =: \tfrac{1}{2} 
  %\,f(\varepsilon) 
  \,\langle \Psi, X \rangle
\]
where the angular brackets indicate the double scalar product over $j$ and $\ell,m$.
For example, for the classical charge as illustrated above, we have 
\[
	[\Psi_j]_\ell^m = {\sqrt{\pi}}\, q_j \, \delta_{\ell,0} \delta_{m,0}.
\]

% THE FOLLOWING IS NOT ENTIRELY CORRECT SINCE THE OVERLAP IN THE INTEGRALS SHOULD BE SUBSTRACTED
%Indeed, the spherical harmonics addition theorem implies that
%\[
%W_j(x) = (\tilde{\cS}_j \, \sigma_j)(x) = \sum_{\ell,m} [X_j]_\ell^m (\tilde{\cS}_j \, Y_\ell^m)(x) = \sum_{\ell,m} [X_j]_\ell^m \, \frac{4\pi}{2\ell+1} \,\frac{r^\ell}{r_j^{\ell+1}} \, Y_\ell^m(y)
%\]
%where $x = x_j + r\, y$, so that the solvation energy can be determined as
%\[
%E_s = \tfrac{1}{2} 
%%\,f(\varepsilon) 
%\, \sum_{j=1}^M \int_{\Omega_j} \rho(x) W_j(x) \, dx = \tfrac{1}{2}
%%\, f(\varepsilon) 
%\, \sum_{j=1}^M \sum_{\ell,m} [X_j]_\ell^m \, \frac{4\pi}{2\ell+1} \,\frac{1}{r_j^{\ell+1}} 
%\int_{\Omega_j} \rho(x) \, r^\ell \, Y_\ell^m(y) \, dx
%\]
%If we define
%\[
%[\Psi_j]_\ell^m = \frac{4\pi}{2\ell+1}\, \frac{1}{r_j^{\ell+1}}\int_{\Omega_j} \rho(x) \, r^\ell \, Y_\ell^m(y) \, dx
%\]
%we can compactly write the energy as
%\[
%E_s = \tfrac{1}{2}
%% \,f(\varepsilon)
% \, \sum_j \sum_{\ell,m} [\Psi_j]_\ell^m [X_j]_\ell^m
%  =: \tfrac{1}{2} 
%  %\,f(\varepsilon) 
%  \,\langle \Psi, X \rangle
%\]
%where the angular brackets indicate the double scalar product over $j$ and $\ell,m$.

The force acting on the $i$-th atom is then given by
\[
\mathcal{F}_i = -\nablai E_s = - \tfrac{1}{2} 
%\,f(\varepsilon) 
\,  \langle \Psi, \nablai X \rangle 
% = - \langle \Psi, \nabla_j\sigma \rangle
\]
where the gradient is understood with respect to $x_i$, and we employed the fact that $\Psi$ is independent of the atomic positions. On the other hand, since the operators $A_\varepsilon$ and $L$, along with the right-hand-side $F$, depend on the nuclear positions, so does the solution $X$ of \eqref{eq:6}. Analogously to the ddCOSMO forces, we proceed to remove the derivative from the unknown $X$ through the solution of the adjoint problem $(A_\varepsilon \, L)^* s = \Psi$, and Leibnitz differentiation rule.

As a first step, differentiation of the COSMO equation $L\, X = G$ yields
\[
\nablai L \, X + L \, \nablai X = \nablai G
\]
so that we can address the term $L \, \nablai X$ in the following expression for the force
\[
\langle \Psi , \nablai X\rangle  = \langle s ,  A_\varepsilon \, L \, \nablai X\rangle
 = \langle s ,  A_\varepsilon \, \nablai G \rangle - \langle s , A_\varepsilon \, \nablai L \,  X \rangle
\]
Secondly, to deal with the term $A_\varepsilon \, \nablai G$, which involves the derivative of the solution to the intermediate PCM step, we differentiate the equation $A_\varepsilon \, G = A_\infty \, F$, namely
\[
\nablai A_\varepsilon \, G + A_\varepsilon \, \nablai G = \nablai A_\infty \, F + A_\infty \, \nablai F
\]
The quantity $\nablai F$ is \emph{a priori} nonzero since $F$ does depend upon the nuclear positions through the characteristic functions, recall \eqref{eq:25}. Since the derivative of $A_\varepsilon$ is independent of $\varepsilon$, we just write $\nablai A$ and obtain
\[
\langle \Psi , \nablai X\rangle = \langle s , \nablai  A ( F - G ) \rangle + \langle  s ,{A_\infty}\, \nablai F \rangle - \langle  s , {A_\varepsilon}\, \nablai L \,  X \rangle
\]
The solution of the adjoint problem $(A_\varepsilon \, L )^* s = \Psi$ requires two steps, namely ${L}^* \, y = \Psi$ and ${A_\varepsilon}^* \, s = y$, so that we can simplify the last term on the right-hand-side, and obtain
\[
\langle \Psi , \nablai X\rangle = \langle s , \nablai  A ( F - G ) \rangle + \langle {A_\infty}^*\, s , \nablai F \rangle - \langle  y , \nablai L \,  X \rangle
\]
{\color{red}
As a last step, we write ${A_\infty}^*\, s = ({A_\infty}-{A_\varepsilon})^*\, s + y$ and observe that ${A_\infty}-{A_\varepsilon} $ is a multiple of the identity, which implies that the adjoint is redundant. The final expression becomes
\[
\langle \Psi , \nablai X\rangle = \langle s , \nablai  A ( F - G ) \rangle + \langle ({A_\infty}-{A_\varepsilon})\, s, \nablai F \rangle +\langle y , \nablai F \rangle - \langle  y , \nablai L \,  X \rangle
\]
where the last two terms coincide with the COSMO force.}

We remark that the PCM-forces we just derived are a perturbation of the COSMO-forces presented in \cite{Lipparini_JCTC_ddCOSMO}. Indeed, when $\varepsilon$ approaches infinity, then $G = F$ and $A_\varepsilon = {A_\infty} $, so that we recover
\[
\langle \Psi , \nablai X\rangle =  \langle y , \nablai F \rangle - \langle y , \nablai L \,  X \rangle
\]
We recall that, because of the sparsity of $L$, and, consequently, its derivative $\nablai L$, the contraction $\langle y ,\nablai L \, X\rangle$ can be computed within a complexity that depends upon $L_\text{max}$, $N_\text{grid}$ and the number of neighbors $N_i$, but is independent of $M$. In other words, it is $O(1)$ with respect to the number of atoms. A similar analysis holds for the contraction $\langle y , \nablai F \rangle$ {\color{red} (Paolo: add comment, maybe...)}. We conclude that, for COSMO, the computation of the $M$ forces acting on each atom is an operation of complexity $O(M)$, with a prefactor that depends at least upon $L_\text{max}$, $N_\text{grid}$, and the average number of neighbors of each atom. As we shall see below, this contrasts with the computation of the PCM-forces, which has complexity $O(M^2)$.

\subsection{Efficient Implementation}

Since the PCM forces are an extension of the COSMO forces, we rely on the analysis in \cite{Lipparini_JCTC_ddCOSMO} for the COSMO contribution, and only need to discuss the additional term $\langle s , \nablai  A ( F - G ) \rangle$. As previously remarked, the operator ${A_\infty} -{A_\varepsilon}$ is a rescaled identity, so that the contraction $\langle ({A_\infty}-{A_\varepsilon})\, s, \nablai F \rangle$ is completely analogous to $\langle y , \nablai F \rangle$ and can be computed in $O(1)$ operations, for each $i$.
 
 
We proceed to establish the complexity of the contraction $\langle s , \nablai  A\, X \rangle$, where we traded $F-G$ for an arbitrary vector $X$, by employing the sparsity of the derivative $\nablai A$. The definition \eqref{eq:ajj} of the diagonal blocks implies that $A_{jj}$ depends upon the nuclear positions $x_j$ and $x_i$ such that $i \in N_j$. Similarly, if we recall \eqref{eq:ajk}, the off-diagonal block $A_{jk}$ depends upon $x_j$, $x_k$, and $x_i$ such that $i \in N_j$. This implies that $\nablai A_{jj}$ is \emph{a priori} nonzero only when $i = j$, or $i \in N_j$. Analogously, $\nablai A_{jk}$ is \emph{a priori} nonzero only when $i = j$, or $i = k$, or $i \in N_j$. In order to restate those conditions for a \emph{fixed} index $i$, and variable indices $j$ and $k$, we make the trivial observation that $i \in N_j$ iff $j \in N_i$. We obtain that $\nablai A_{jj}$ is \emph{a priori} nonzero only when $j = i$, or $j \in N_i$, and $\nablai A_{jk}$ is \emph{a priori} nonzero only when $j= i$, or $k = i$, or $j \in N_i$.

We employ the previous vanishing conditions to compute the contraction $\langle s , \nablai A\,X \rangle$. We rearrange the summations as
\[
\sum_{k,j} s_j \, \nablai A_{jk} \, X_k =  s_i \, \sum_k \, \nablai A_{ik} \, X_k + X_i \, \sum_{j \not=i} \, s_j \, \nablai A_{ji}  + \sum_{k\not=i} \,X_k \,\sum_{j\not=i} \, s_j \, \nablai A_{jk}
\]
Each term on the right-hand-side that involves a single summation requires a $O(M)$ computation cost, with a prefactor that depends at least upon $L_\text{max}$ and $N_\text{grid}$. The range of index $j$ in the double summation term simplifies to $N_i$ because of the vanishing conditions. Thus, its computation requires $O(M)$ operations as well, although with a prefactor that also depends upon the average number of neighbors.

The cost of computing the force acting on the $i$-th atom is dominate by the cost of the contraction $\langle s , \nablai  A ( F - G ) \rangle$. We conclude that the computation cost of the $M$ contractions needed for the PCM forces acting on each atom is $O(M^2)$, with the prefactor that depends at least upon $L_\text{max}$, $N_\text{grid}$, and the average number of neighbors of each atom.


%In order to estimate the computational cost of $( \nablai A \, X)_j$ for fixed $i$, we isolate the diagonal block as
%\begin{equation}\label{eq:70}
%( \nablai A \, X)_j = \nablai A_{jj} \, X_j + \sum_{k\not=j} \,\nablai A_{jk} \, X_k
%\end{equation}
%The straightforward cost of this operation is $O(M)$, with a prefactor that depends upon $L_\text{max}$ and $N_\text{grid}$. We proceed to vary the index $j$. The choice $j = i$ does not yield any simplification in \eqref{eq:70}, as is also the case for the choice $j$ such that $i \in N_j$. On the other hand, the complementary case, i.e., $j \not=i$ and such that $i \not\in N_j$, yields the simplified expression
%\[
%( \nablai A \, X)_j = \nablai A_{ji} \, X_i
%\]
%whose computational cost is $O(1)$, again with a prefactor that depends upon $L_\text{max}$ and $N_\text{grid}$.
%
%The less favorable case of computation complexity $O(M)$ occurs for a number of entries of the order of the average number of neighbors. On the other hand, the case the more favorable case $O(1)$ occurs for roughly $M$ entries. The total computational complexity of computing the action is $O(M)$. Nevertheless, $\nablai A \, X$ is fully populated, as opposed to $\nablai L \, X$ which is sparse. This implies that a single contraction product $\langle s , \nablai A \, X \rangle$ has computational complexity $O(M)$, so that the computation of the forces has complexity $O(M^2)$, with a prefactor that depends at least upon $L_\text{max}$, $N_\text{grid}$, and the average number of neighbors of each atom.

{\color{red} Paolo: after we are sure that the above complexity analysis is correct, we can remove everything below.}

\noindent
{\bf A quick overview of sparsity of $\nablai A_{jk}$}: There is nothing new, but should clarify a bit the computational complexity of computing the forces.
\begin{itemize}
\item {\bf Diagonal terms: $j=k$:}
	\begin{itemize}
		\item If $i\in N_j=N_k$ or $i=j=k$, then $[ \nablai A_{jj}]_{\ell \ell'}^{m m'} \neq 0$. 
		\item If $i\not \in N_j=N_k$ and  $i\neq j=k$, then $[ \nablai A_{jk}]_{\ell \ell'}^{m m'} = 0$.
	\end{itemize}
\item {\bf Off-diagonal terms: $j\neq k$:}
	\begin{itemize}
		\item If $i=k$, then $[ \nablai A_{jk}]_{\ell \ell'}^{m m'} \neq 0$.
		\item If $i=j$, then $[ \nablai A_{jk}]_{\ell \ell'}^{m m'} \neq 0$.
		\item If $i\neq j$ and $i\neq k$
		\begin{itemize}
			\item If $i\in N_j$ and $i\neq k$, then $[ \nablai A_{jk}]_{\ell \ell'}^{m m'} \neq 0$.
			\item If $i\not\in N_j$ and $i\neq k$, then $[ \nablai A_{jk}]_{\ell \ell'}^{m m'} =0 0$.
		\end{itemize}
	\end{itemize}
\end{itemize}
From a different perspective, we want now to analyse the complexity of the matrix-vector product $\nablai A f$ for some vector $f$.
%

We see that 
\begin{align*}
	[(\nablai A f)_j]_\ell^m 
	&= \sum_k \sum_{\ell',m'} [\nablai A_{jk}]_{\ell \ell'}^{m m'} [f_k]_{\ell'}^{m'} \\
	&= \sum_{\ell',m'} [\nablai A_{jj}]_{\ell \ell'}^{m m'} [f_j]_{\ell'}^{m'} 
	+ \sum_{k\neq j} \sum_{\ell',m'} [\nablai A_{jk}]_{\ell \ell'}^{m m'} [f_k]_{\ell'}^{m'} 
\end{align*}
so that we split $\nablai A$ into the block-diagonal part $\nablai A_d$ and the off-diagonal part $\nablai A_o$.
\begin{align*}
	[(\nablai A_d f)_j]_\ell^m 
	&= \sum_{\ell',m'} [\nablai A_{jj}]_{\ell \ell'}^{m m'} [f_j]_{\ell'}^{m'} \\
	[(\nablai A_o f)_j]_\ell^m 
	&= \sum_{k\neq j} \sum_{\ell',m'} [\nablai A_{jk}]_{\ell \ell'}^{m m'} [f_k]_{\ell'}^{m'} 
\end{align*}
For the diagonal part, we have that
\[
	[(\nablai A_d f)_j]_\ell^m = 0
\]
if $i\not\in N_j$ and $i\neq j$. For a fixed $i$, the number of non-zero contributions (indexed by $j$) from the diagonal is independent of $M$. $\mathcal O(1)$

For the off-diagonal part, we distinguish three cases.

Case 1 ($i=j$ and necessarily $i\neq N_j$):
\[
	[(\nablai A_o f)_i]_\ell^m 
	= 	\sum_{k\neq i} \sum_{\ell',m'} [\nablai A_{ik}]_{\ell \ell'}^{m m'} [f_k]_{\ell'}^{m'} 
\]
Here, all terms $k\neq i$ must be considered. This operation is $\mathcal O(M)$ but this case happens for one $j$ only.

Case 2 ($i\neq j$ and $i\in N_j$):
\[
	[(\nablai A_o f)_j]_\ell^m 
	= \sum_{\ell',m'} [\nablai A_{ji}]_{\ell \ell'}^{m m'} [f_i]_{\ell'}^{m'} 
	+ \sum_{k\neq j, k\neq i} \sum_{\ell',m'} [\nablai A_{jk}]_{\ell \ell'}^{m m'} [f_k]_{\ell'}^{m'} 
\]
This operation is $\mathcal O(M)$, but this case happens for $\mathcal O(1)$ values of $j$ only.

Case 3 ($i\neq j$ and $i\not \in N_j$):
\[
	[(\nablai A_o f)_j]_\ell^m 
	= \sum_{\ell',m'} [\nablai A_{ji}]_{\ell \ell'}^{m m'} [f_i]_{\ell'}^{m'} 
\]
This operation is $\mathcal O(1)$ and this needs to be done for $\mathcal O(M)$ values of $j$.

Therefore, we see that computing all coefficients of the matrix-vector product $[(\nablai A f)_j]_\ell^m $ for one fixed $i$ requires $\mathcal O(M)$ of operations. 
Now, this needs to be done for each $i=1,\ldots,M$ such that the overall complexity to compute all coefficients $[(\nablai A f)_j]_\ell^m $ for all $i$ and $j$ is $\mathcal O(M^2)$.



%1. Use that $\nablai A_\infty=\nablai A_\varepsilon$ and that $L \, X=G$:
%\begin{alignat*}{1}
%h_i &= \nablai A_\infty \, F +  A_\infty \, \nablai F - \nablai A_\varepsilon \, L \, X -  A_\varepsilon \, \nablai L \, X\\
%&= \nablai A \, (F-  G) +  A_\infty \, \nablai F  -  A_\varepsilon \, \nablai L \, X
%\end{alignat*}
%
%2. Explain how to do the following operations efficiently:
%\begin{alignat*}{3}
%\langle s, \nablai A \, (F-  G) \rangle &= \langle (\nablai A)^* \, s,  F-  G \rangle ? \\
%\langle s, A_\infty \, \nablai F \rangle &= \langle A_\infty \,^* \, s,  \nablai F \rangle \\
%\langle s, A_\varepsilon \, \nablai L \, X \rangle &= \langle (A_\varepsilon\, \nablai L)^* \, s,  X \rangle ? \\
%\end{alignat*}
%I don't see how the first and third term are efficiently done in practice?
%
%3. Use the skew-symmetric relationship from above.
